{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stop_words = set(stopwords.words('english')) \n",
    "def sent2word(x):\n",
    "    x=re.sub(\"[^A-Za-z]\",\" \",x)\n",
    "    x.lower()\n",
    "    filtered_sentence = [] \n",
    "    words=x.split()\n",
    "    for w in words:\n",
    "        if w not in stop_words: \n",
    "            filtered_sentence.append(w)\n",
    "    return filtered_sentence\n",
    "\n",
    "def essay2word(essay):\n",
    "    essay = essay.strip()\n",
    "    tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    raw = tokenizer.tokenize(essay)\n",
    "    final_words=[]\n",
    "    for i in raw:\n",
    "        if(len(i)>0):\n",
    "            final_words.append(sent2word(i))\n",
    "    return final_words\n",
    "\n",
    "\n",
    "def makeVec(words, model, num_features):\n",
    "    vec = np.zeros((num_features,), dtype=\"float32\")\n",
    "    noOfWords = 0\n",
    "    for i in words:\n",
    "        if i in model:\n",
    "            noOfWords += 1\n",
    "            vec = np.add(vec, model[i])\n",
    "    if noOfWords > 0:\n",
    "        vec = np.divide(vec, noOfWords)\n",
    "    return vec\n",
    "\n",
    "\n",
    "def getVecs(essays, model, num_features):\n",
    "    c=0\n",
    "    essay_vecs = np.zeros((len(essays),num_features),dtype=\"float32\")\n",
    "    for i in essays:\n",
    "        essay_vecs[c] = makeVec(i, model, num_features)\n",
    "        c+=1\n",
    "    return essay_vecs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Word2Vec model from the binary file\n",
    "word2vec_model = KeyedVectors.load_word2vec_format('word2vecmodel.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_essays = [\" In the grand tapestry of human innovation, few threads shine as brightly as the computer. A marvel of modern ingenuity, the computer stands as a testament to humanity's insatiable curiosity and unyielding drive for progress. It is more than just a machine; it is a gateway to boundless possibilities, a portal to realms of knowledge and imagination. At its core, the computer is a symphony of silicon and circuitry, a labyrinth of ones and zeros woven into the fabric of our digital age. Yet, its true essence transcends mere hardware and software. It is a catalyst for creativity, a canvas upon which dreams are painted in pixels. From the intricate lines of digital art to the melodic harmonies of electronic music, the computer empowers artists to push the boundaries of expression. But the computer is not just a tool for the creative mind; it is also a beacon of connectivity in an increasingly interconnected world. With a few keystrokes, we can traverse vast virtual landscapes, connecting with friends and strangers alike across oceans and continents. Social media platforms, online forums, and virtual communities serve as digital watering holes where ideas flow freely, and bonds are forged in the digital ether. Moreover, the computer is a wellspring of knowledge, a repository of humanity's collective wisdom. With a few clicks, we can access a wealth of information spanning the breadth of human understanding. From the mysteries of the cosmos to the intricacies of quantum mechanics, the computer opens doors to realms once reserved for the privileged few. Yet, for all its wonders, the computer is not without its pitfalls. In the labyrinth of cyberspace, dangers lurk in the shadows, from cybercrime to information warfare. As we navigate this digital frontier, we must remain vigilant, guarding against the dark forces that seek to exploit our vulnerabilities. In the end, the computer is more than just a machine; it is a reflection of humanity itself—flawed yet full of promise. It is a tool for both creation and destruction, a mirror that reflects the best and worst of who we are. As we stand on the cusp of a new digital era, let us wield this power wisely, harnessing the potential of the computer to shape a brighter tomorrow for generations to come.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_new_essays = [sent2word(essay) for essay in new_essays]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 300\n",
    "# Generating vectors for the new essays using the loaded Word2Vec model\n",
    "new_essay_vectors = getVecs(preprocessed_new_essays, word2vec_model, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the vectors\n",
    "new_essay_vectors = np.array(new_essay_vectors)\n",
    "new_essay_vectors = np.reshape(new_essay_vectors, (new_essay_vectors.shape[0], 1, new_essay_vectors.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "lstm_model = load_model('final_lstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478ms/step\n",
      "Predictions: [[9.]]\n"
     ]
    }
   ],
   "source": [
    "# Predicting scores for the new essays using the LSTM model\n",
    "predictions = lstm_model.predict(new_essay_vectors)\n",
    "predictions = np.around(predictions)\n",
    "print(\"Predictions:\", predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
